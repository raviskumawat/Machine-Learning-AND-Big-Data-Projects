{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import face_recognition\n",
    "import dlib\n",
    "import re\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "def give_embedding(img_):\n",
    "    img=cv2.resize(img_,(256,256),interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    #extract gray img\n",
    "    #gray_img=np.eye(256)\n",
    "    gray_img=cv2.cvtColor(img.copy(),cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    # Create a HOG face detector using the built-in dlib class\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    #print(image)\n",
    "    face=face_detector(gray_img,1)\n",
    "    if len(face)<1:\n",
    "        \n",
    "        return []\n",
    "    #detected_faces=face\n",
    "    face=face[0]\n",
    "    #face_img=cv2.rectangle(img,(detected_faces[0].left(),detected_faces[0].top()),(detected_faces[0].right(),detected_faces[0].bottom()),(0,255,0),1)\n",
    "    face_img=img[face.top():face.bottom(),face.left():face.right()]\n",
    "    face_embedding=np.array(face_recognition.face_encodings(face_img)).ravel()\n",
    "    return np.array(face_embedding).ravel()\n",
    "\n",
    "\n",
    "def load_small_img_dataset(path=os.getcwd()):\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    for i,image in enumerate(os.listdir(path)):\n",
    "        if image.endswith(('.jpg','.jpeg','.png','bmp')):\n",
    "            #print(image)\n",
    "            label=re.findall('^(.*)_.*',image)[0]\n",
    "            pixels=cv2.imread(os.path.join(path,image))\n",
    "            #first make all images of same size using crop\n",
    "            face_embedding=give_embedding(pixels)\n",
    "            if len(face_embedding)<1:\n",
    "                print('face cannot be detected in {0}  [IGNORING]'.format(image))\n",
    "                continue\n",
    "            data.append(face_embedding)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return data,labels\n",
    "\n",
    "def test_train_dev_split(input_data,output_data,train=0.7,dev=0.2,test=0.1):\n",
    "    #make seed for exact results everything\n",
    "    #random.sort(dataset)\n",
    "    #np.random.seed(2)\n",
    "    #np.random.shuffle(input_data)\n",
    "    #np.random.shuffle(output_data)\n",
    "    input_data, output_data = shuffle(input_data, output_data, random_state=0)\n",
    "    split1=int(train*len(input_data))\n",
    "    split2=int((train+dev)*len(input_data))\n",
    "    train_input=input_data[:split1]\n",
    "    dev_input=input_data[split1:split2]\n",
    "    test_input=input_data[split2:]\n",
    "    \n",
    "    \n",
    "    train_output=output_data[:split1]\n",
    "    dev_output=output_data[split1:split2]\n",
    "    test_output=output_data[split2:]\n",
    "    \n",
    "    return np.array(train_input),np.array(train_output),np.array(dev_input),np.array(dev_output),np.array(test_input),np.array(test_output)\n",
    "\n",
    "\n",
    "\n",
    "def train_svm(datapath):\n",
    "    x,y=load_small_img_dataset(datapath)\n",
    "    X=np.ones((len(x),128),dtype=np.float64)\n",
    "    for i,sample in enumerate(x):\n",
    "        for j,val in enumerate(sample):\n",
    "            X[i][j]=val\n",
    "\n",
    "    persons=set(y)\n",
    "    num_persons=len(set(y))\n",
    "    categorical_mapping={}\n",
    "\n",
    "    #convert into one hot encoding\n",
    "    for i,name in enumerate(persons):\n",
    "        #print(i,name)\n",
    "        categorical_mapping[name]=i\n",
    "\n",
    "    output_d=[]\n",
    "\n",
    "    for i_ in y:\n",
    "        i_=categorical_mapping[i_]\n",
    "        output_d.append(i_)\n",
    "    #output_d=to_categorical(output_d)\n",
    "\n",
    "    oneHot2Name={}\n",
    "    for i in categorical_mapping.keys():\n",
    "        oneHot2Name[categorical_mapping[i]]=i\n",
    "        \n",
    "    np.save('oneHot2Name.npy',oneHot2Name)\n",
    "\n",
    "\n",
    "\n",
    "    train_input,train_output,dev_input,dev_output,test_input,test_output=test_train_dev_split(X,output_d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    #No need as dealing with encodings not images\n",
    "    \n",
    "    cv2.imshow(oneHot2Name[np.argmax(train_output[13])],train_input[13])\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # to convert our data type to float32 and normalize our database\n",
    "    train_input=train_input.astype('float32')\n",
    "    dev_input=dev_input.astype('float32')\n",
    "    test_input=test_input.astype('float32')\n",
    "    print(train_input.shape)\n",
    "    print(test_input.shape)\n",
    "    \n",
    "    \n",
    "    # Z-scoring or Gaussian Normalization\n",
    "    train_input=train_input - np.mean(train_input) / train_input.std()\n",
    "    dev_input=dev_input - np.mean(dev_input) / dev_input.std()\n",
    "    test_input=test_input - np.mean(test_input) / test_input.std()\n",
    "    categorical_mapping\n",
    "    \n",
    "    \n",
    "    train_input=train_input/255.0\n",
    "    dev_input=dev_input/255.0\n",
    "    test_input=test_input/255.0'''\n",
    "    \n",
    "\n",
    "    # Train SVM classifier\n",
    "    SVMmodel= SVC(C=1.0, kernel=\"linear\", probability=True)\n",
    "    SVMmodel.fit(train_input,train_output) \n",
    "    print(\"Model score: {0}\".format(SVMmodel.score(test_input, test_output)))\n",
    "    print(\"predicted: {0}    Actual: {1}\".format(SVMmodel.predict(test_input),test_output))\n",
    "    \n",
    "    with open('SVMmodel.pickle', 'wb') as file:\n",
    "        file.write(pickle.dumps(SVMmodel))\n",
    "    \n",
    "    return SVMmodel\n",
    "\n",
    "\n",
    "def recognise_img_SVM(test_img,train=False):\n",
    "    if train==True:\n",
    "        model=train_svm('D:\\dataset\\Image\\Face Dataset custom')\n",
    "    else:\n",
    "        with open('SVMmodel.pickle', 'rb') as file:\n",
    "            model = pickle.loads(open('SVMmodel.pickle', \"rb\").read())\n",
    "    oneHot2Name=np.load('oneHot2Name.npy').item()\n",
    "    \n",
    "    #Test Image\n",
    "    embd=give_embedding(test_img)\n",
    "    \n",
    "    if len(embd)<1:\n",
    "        return 'unknown'\n",
    "    predicted=model.predict(np.array(embd).reshape(1,128))\n",
    "    print(\"predicted: {0} \".format(oneHot2Name[predicted[0]]))\n",
    "    #cv2.imshow(oneHot2Name[predicted[0]],cv2.imread(test_img))\n",
    "    #cv2.waitKey()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return oneHot2Name[predicted[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: Das \n",
      "Das\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_img=cv2.imread('S_.jpg')\n",
    "    x=recognise_img_SVM(test_img)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
